{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchaudio.models.decoder import ctc_decoder\n",
    "import os\n",
    "import torchaudio\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7]\n",
      "-a-b-c-d-e-\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {\n",
    "    ' ': 0,\n",
    "    \"'\": 1,\n",
    "    'a': 2,\n",
    "    'b': 3,\n",
    "    'c': 4,\n",
    "    'd': 5,\n",
    "    'e': 6,\n",
    "}\n",
    "string = \"abcde\"\n",
    "int_list = [char_to_int[char]+char_to_int['\\''] for char in string]\n",
    "\n",
    "print(int_list)\n",
    "result = \"-\"+\"-\".join(string) + \"-\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = os.path.join(os.getcwd(), 'models')\n",
    "lexicon_file = \"lexicon.txt\"\n",
    "lexicon_path = os.path.join(folder_dir, lexicon_file)\n",
    "lm_file = \"lm.bin\"\n",
    "lm_path = os.path.join(folder_dir, lm_file)\n",
    "acoustic_file = \"states.pth\"\n",
    "acoustic_path = os.path.join(folder_dir, acoustic_file)\n",
    "labels = [\n",
    "    \" \",\n",
    "    *\"abcdefghijklmnopqrstuvwxyz\",\n",
    "    \"'\",\n",
    "    \"*\"\n",
    "]\n",
    "tokens = ['-', '|', 'e', 't', 'a', 'o', 'n', 'i', 'h', 's', 'r', 'd', 'l', 'u',\n",
    "          'm', 'w', 'c', 'f', 'g', 'y', 'p', 'b', 'v', 'k', \"'\", 'x', 'j', 'q', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "model = bundle.get_model()\n",
    "torch.save(model,'base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('models/weights.pt')\n",
    "model = torch.load('models/base.pt')\n",
    "acoustic_model = Model(num_classes=len(labels))\n",
    "acoustic_model.load_state_dict(torch.load(acoustic_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_WEIGHT = 3.23\n",
    "WORD_SCORE = -0.26\n",
    "blank_token = '*'\n",
    "sil_token = ' '\n",
    "my_decoder = ctc_decoder(\n",
    "    lexicon=lexicon_path,\n",
    "    tokens=labels,\n",
    "    lm=lm_path,\n",
    "    lm_weight=LM_WEIGHT,\n",
    "    word_score=WORD_SCORE,\n",
    "    blank_token=blank_token,\n",
    "    sil_token=sil_token\n",
    ")\n",
    "ctc_decode = ctc_decoder(\n",
    "    lexicon=lexicon_path,\n",
    "    tokens=tokens,\n",
    "    lm=lm_path,\n",
    "    beam_size_token=len(tokens),\n",
    "    lm_weight=LM_WEIGHT,\n",
    "    word_score=WORD_SCORE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to: test.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "def record_audio(duration, sample_rate=16000, file_path=\"test.wav\"):\n",
    "    # Set the sample rate and duration\n",
    "    duration_in_samples = int(duration * sample_rate)\n",
    "\n",
    "    # Record audio\n",
    "    audio = sd.rec(frames=duration_in_samples,\n",
    "                   samplerate=sample_rate, channels=1, blocking=True)\n",
    "\n",
    "    # Save audio to file\n",
    "    sf.write(file_path, audio, sample_rate)\n",
    "\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# Example usage: Record audio for 5 seconds at a sample rate of 16000 Hz and save to \"recorded_audio.wav\"\n",
    "audio_file = record_audio(duration=3, sample_rate=16000,\n",
    "                          file_path=\"test.wav\")\n",
    "print(\"Audio saved to:\", audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "print(\"Sample rate:\", sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    emission, _ = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcribe(audio_file, acoustic_model, my_decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_result = ctc_decode(emission)\n",
    "beam_search_transcript = \" \".join(beam_search_result[0][0].words).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Transcript: {beam_search_transcript}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python39\\lib\\site-packages\\torchaudio\\models\\decoder\\_ctc_decoder.py:62: UserWarning: The built-in flashlight integration is deprecated, and will be removed in future release. Please install flashlight-text. https://pypi.org/project/flashlight-text/ For the detail of CTC decoder migration, please see https://github.com/pytorch/audio/issues/3088.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import main\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded\n"
     ]
    }
   ],
   "source": [
    "model, decoder = utils.load_files_mod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a beautiful girl\n"
     ]
    }
   ],
   "source": [
    "print(main.transcribe_mod(audio_file, model, decoder))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
