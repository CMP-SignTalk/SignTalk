{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2725218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import layers\n",
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM , Dense \n",
    "from keras.callbacks import TensorBoard\n",
    "import os \n",
    "import gtts \n",
    "from playsound import playsound \n",
    "import cv2 \n",
    "import time \n",
    "import mediapipe as mp \n",
    "import numpy as np \n",
    "import gtts \n",
    "from playsound import playsound \n",
    "import shutil\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "import json \n",
    "import os \n",
    "import cv2\n",
    "import mediapipe as mp \n",
    "import numpy as np \n",
    "import threading \n",
    "import numpy as np\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2076b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"\n",
    "    Performs detection using the MediaPipe library.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray)  : The input image to be processed. It should be in BGR format.\n",
    "        model (MediaPipe Model): The detection model to be used for processing the image.\n",
    "\n",
    "    Returns:\n",
    "        image (numpy.ndarray)      : The processed image with detections overlaid. It is in BGR format.\n",
    "        results (MediaPipe Results): The detection results obtained from the model.\n",
    "    \"\"\"\n",
    "    # Convert image to RGB format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Make the image writeable flag as False to improve performance\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Perform detection using the provided model\n",
    "    results = model.process(image)\n",
    "\n",
    "    # Make the image writeable flag as True to modify it\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    # Convert the image back to BGR format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Return the processed image and the detection results\n",
    "    return image, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54293ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_nose_x = None ; \n",
    "temp_nose_y = None ; \n",
    "\n",
    "\n",
    "def extract_keypoints(results,temp_nose_x,temp_nose_y):\n",
    "    \"\"\"\n",
    "    Extracting the Holistic keypoints from the left and the right hand. \n",
    "    Args:\n",
    "    results ()        : the detection results obtained from the image \n",
    "    temp_nose_x (int) : the X coordinate of the clown point \n",
    "    temp_nose_y (int) : the Y coordinate of the clown point \n",
    "       \n",
    "\n",
    "    Returns:\n",
    "    lh (numpy.ndarray) :  the coordinates of the left  hand keypoints in the image\n",
    "    rh (numpy.ndarray) :  the coordinates of the right hand keypoints in the image\n",
    "      \n",
    "\n",
    "    Description:\n",
    "    \n",
    "    This function holds significant importance in the project as it is responsible for \n",
    "    extracting holistic features from both hands and formatting them appropriately for \n",
    "    training purposes.\n",
    "\n",
    "    One impressive aspect of this function is its ability to make the model translation-invariant.\n",
    "    This means that regardless of whether the user is sitting with respect to the camera, \n",
    "    the model remains capable of accurately detecting the sign.\n",
    "\n",
    "    The clown point, extracted from the pose model in mediapipe, plays a crucial role in this function. \n",
    "    The clown point is located at the edge of the nose and serves as a reference point for all other \n",
    "    points. By utilizing this point, the model learns the distance between the holistic features in \n",
    "    the hand and the clown point, effectively enhancing its translation invariance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # getting the x coordinate of the clown point \n",
    "        # if it does not exist use the previous one (some times the model will not detect the nose )\n",
    "        # so we will use the previous one \n",
    "        X_Nose=results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x\n",
    "        temp_nose_x=X_Nose\n",
    "    except : \n",
    "        X_Nose = temp_nose_x\n",
    "    try : \n",
    "        Y_Nose=results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y\n",
    "        temp_nose_y=Y_Nose\n",
    "    except : \n",
    "        Y_Nose= temp_nose_y \n",
    "    lh = np.array([[result.x - X_Nose, result.y - Y_Nose, result.z] for result in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[result.x - X_Nose, result.y - Y_Nose, result.z] for result in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3) \n",
    "    return np.concatenate([lh,rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e5c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the holistic model \n",
    "mp_holistic = mp.solutions.holistic\n",
    "# loading the pose model \n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determing the number of frames that will be extracted from one video \n",
    "\n",
    "frames_num=40 ; \n",
    "def generate_training_data(all_vids,path_to_working_dir):\n",
    "    \"\"\"\n",
    "    Generating Training Data\n",
    "\n",
    "    Args:\n",
    "    all_Vids (list)          : A list of all sign folders, e.g., [\"Hello\", \"Live\", \"Love\"].\n",
    "    path_to_working_dir (str): The path to the directory of the videos.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    None: This function does not return anything; it saves the keypoints in the file system.\n",
    "    \n",
    "    \n",
    "    Description:\n",
    "    This function takes the path to the sign folders and iterates over each sign in the folder.\n",
    "    It extracts the features for each video in the sign folder, concatenates them, and saves them.\n",
    "    \"\"\"\n",
    "    # loop over all the signs \n",
    "    for j,k in enumerate(all_vids):\n",
    "        # enter every sign folder \n",
    "        path_to_videos=os.path.join(path_to_working_dir,k)\n",
    "        print(path_to_videos)\n",
    "        # get the number of videos within the sign folder \n",
    "        vids_num = len(os.listdir(path_to_videos))\n",
    "        print(vids_num) \n",
    "        # initialize the array of the data \n",
    "        current_data=np.zeros((vids_num,frames_num,126))\n",
    "        for i in range (vids_num): # loop through 30 video \n",
    "            path_to_current_sign= os.path.join(path_to_videos,f\"output{i}.avi\")\n",
    "            \n",
    "            # min_detection_confidence:The minimum confidence score for the hand detection to be \n",
    "            #considered successful in palm detection model.\n",
    "            \n",
    "            # min_tracking_confidence : The minimum confidence score for the hand tracking to be considered successful.\n",
    "            #This is the bounding box IoU threshold between hands in the current frame and the last frame.\n",
    "            #In Video mode and Stream mode of Hand Landmarker, if the tracking fails, Hand Landmarker \n",
    "            #triggers hand detection. Otherwise, it skips the hand detection.\n",
    "            \n",
    "            # start using the holistic model \n",
    "            with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic :\n",
    "                # check that the current sign folder exists \n",
    "                if os.path.exists(path_to_current_sign):\n",
    "\n",
    "                    index = 0 \n",
    "                    cap = cv2.VideoCapture(path_to_current_sign);  \n",
    "                    length= int (cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    rest = length\n",
    "                    start_frame =False \n",
    "                    # check that the video has the min number of frames required for extracting \n",
    "                    # meaningful information from it \n",
    "                    if(length>frames_num):\n",
    "                        # open the vid \n",
    "                        while (cap.isOpened()):\n",
    "                            ret , frame = cap.read()\n",
    "                            # check if the cap return frame \n",
    "                            # and check if you have taken the required frames or not \n",
    "                            if ret == True and index<frames_num:  # keeping only the first 40 frame \n",
    "                                # detection  \n",
    "                                image, results = mediapipe_detection(frame, holistic)\n",
    "                                # extrating the keypoints \n",
    "                                keypoints = extract_keypoints(results,temp_nose_x,temp_nose_y)\n",
    "                                \n",
    "                                # start_frame will indicate if the model has detecetd a frame that \n",
    "                                # has some meaningful info . \n",
    "                                # meaningful means that not all value are zero ,as in the beginning\n",
    "                                # of the video the singer starts by his hand not in the scope of the \n",
    "                                # camera , so this frames are not useful , all their values will be zero \n",
    "                                \n",
    "                                # while the rest of the frames is more than the required number \n",
    "                                # and not strat frame \n",
    "                                if not(start_frame) and rest>frames_num:\n",
    "                                    # if all ponits are zero and you didn't get any points before \n",
    "                                    # skip that frame as the number of rest frames is more than \n",
    "                                    # the required ones \n",
    "                                    if (np.all(keypoints==0)):\n",
    "                                        rest-=1 \n",
    "                                        continue\n",
    "                                    else :\n",
    "                                        start_frame=True\n",
    "\n",
    "                                current_data[i][index]=keypoints\n",
    "\n",
    "                                index+=1 \n",
    "                            else :\n",
    "                                print(f\"this is video {i+1}\")\n",
    "                                break \n",
    "\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "\n",
    "#         print(\"I am here will write to file \")\n",
    "#         print(current_data[i])\n",
    "      \n",
    "        write_path = os.path.join(path_to_working_dir,k)\n",
    "        print(write_path)\n",
    "        if os.path.exists(write_path):\n",
    "            print(\"yes\")\n",
    "            # save the data \n",
    "            np.save(os.path.join(write_path,\"no_aug\"),current_data)\n",
    "        else : \n",
    "            pass \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_data(all_vids,sign,path_to_working_dir,additional=False):\n",
    "    \"\"\"\n",
    "    collect all the data of the one sign\n",
    "\n",
    "    Args:\n",
    "    all_Vids (list)           : List of all signs folder e.g.[\"Hello\",\"Live\",\"Love\"] etc  \n",
    "    path_to_working_dir (str) : Path to the directory of the vids \n",
    "    additional(boolean)       : boolean to indicate if this data is original or additional \n",
    "       \n",
    "    Returns:\n",
    "    None : nothing returned just save the keypoints in the file system \n",
    "      \n",
    "\n",
    "    Description:\n",
    "    Collect the data for the training processes , concatenate all the data of the differnent signs\n",
    "    \"\"\"\n",
    "    X_train_no_aug=np.load(os.path.join(path_to_working_dir,all_vids[0],\"no_aug.npy\"))\n",
    "    vids_num = X_train_no_aug.shape[0] \n",
    "    Y_train_no_aug=np.array([all_vids[0]]*vids_num)\n",
    "    print(vids_num)\n",
    "\n",
    "    for i in range (1, len(all_vids)):\n",
    "        X_train_no_aug_temp=np.load(os.path.join(path_to_working_dir,all_vids[i],\"no_aug.npy\"))\n",
    "        vids_num =  X_train_no_aug_temp.shape[0]\n",
    "        print(vids_num)\n",
    "        X_train_no_aug = np.concatenate([X_train_no_aug,X_train_no_aug_temp],axis=0)\n",
    "        lst=[]\n",
    "        lst.append(all_vids[i])\n",
    "        Y_train_no_aug=np.concatenate([Y_train_no_aug,lst*vids_num])\n",
    "\n",
    "    if additional : \n",
    "        np.save(os.path.join(path_to_working_dir,f\"Data_train_clown_40_no_aug_yes_no_{sign}_additional.npy\"),X_train_no_aug)\n",
    "        np.save(os.path.join(path_to_working_dir,f\"Data_labels_clown_40_no_aug_yes_no_{sign}_additional.npy\"),Y_train_no_aug)\n",
    "    else :\n",
    "        np.save(os.path.join(path_to_working_dir,f\"Data_train_clown_40_no_aug_yes_no_{sign}.npy\"),X_train_no_aug)\n",
    "        np.save(os.path.join(path_to_working_dir,f\"Data_labels_clown_40_no_aug_yes_no_{sign}.npy\"),Y_train_no_aug)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ef223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_model(signs):\n",
    "    \"\"\"\n",
    "    Creating the model.\n",
    "\n",
    "    Args:\n",
    "    Sings (dictionanry ) : dictionary contains all the signs in the vocab \n",
    "       \n",
    "    Returns:\n",
    "    model : Sequentail model , Recurrent Neural network . \n",
    "      \n",
    "\n",
    "    Description:\n",
    "    Creating the model that is required before training . \n",
    "    \"\"\"\n",
    "    model=Sequential()\n",
    "#     print(\"IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\",len(signs))\n",
    "    model.add(LSTM(64,return_sequences=False ,activation='relu',input_shape=(40,126)))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(signs), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_old_model(signs,sign_name):\n",
    "    \"\"\"\n",
    "    Loading Old Models for Re-training or Testing\n",
    "\n",
    "    Args:\n",
    "\n",
    "    Signs (dictionary): A dictionary that contains all the signs in the vocabulary.\n",
    "    sign_name (str): The name of the sign whose model will be loaded.\n",
    "    Returns:\n",
    "\n",
    "    model: Sequential model, Recurrent Neural Network.\n",
    "    Description:\n",
    "    This function loads a pre-saved model for retraining or using it in the detection of new videos. It takes the dictionary of signs and the name of the sign whose model needs to be loaded as input.\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating the model\n",
    "    model = create_model(signs)\n",
    "    # load its weights \n",
    "    model.load_weights(os.path.join(os.getcwd(),\"models\",f\"{sign_name}_model.h5\"))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,model_path=\"Iam_model.h5\"):\n",
    "        \"\"\"\n",
    "        Constructor of the Callback Class for Initializing Accuracies\n",
    "\n",
    "        Args:\n",
    "\n",
    "        model_path (str): The path at which the model will be saved.\n",
    "        Returns:\n",
    "\n",
    "        None\n",
    "        Description:\n",
    "        This constructor initializes the Callback class and is used for initializing accuracies. It takes the model path as input and does not return anything.\n",
    "        \"\"\"\n",
    "        self.max_val_acc=0\n",
    "        self.max_tra_acc=0\n",
    "        self.model_path=model_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Performing Actions at the End of Each Epoch\n",
    "\n",
    "        Description:\n",
    "        This function is called at the end of each epoch to perform certain actions. \n",
    "        Specifically, it saves the model if the accuracy achieved in the last epoch is \n",
    "        better than the accuracy of the current saved model.\n",
    "        \"\"\"\n",
    "        tra_acc= logs.get(\"accuracy\")\n",
    "        if(tra_acc>0.98):\n",
    "            self.model.stop_training=True \n",
    "            \n",
    "        \n",
    "        if  tra_acc > self.max_tra_acc :\n",
    "            self.tra_acc=tra_acc\n",
    "            self.model.save(self.model_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc516eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_data(X_train, Y_train,alphabets): \n",
    "    \"\"\"\n",
    "    Performing Checks on the Training Data and Label Conversion\n",
    "\n",
    "    Args:\n",
    "\n",
    "    X_train (numpy.ndarray): Numpy array containing the training data.\n",
    "    Y_train (numpy.ndarray): Numpy array containing the labels of the training data.\n",
    "    Returns:\n",
    "\n",
    "    None\n",
    "    Description:\n",
    "    \n",
    "    This function performs checks on the training data to ensure its validity for training. \n",
    "    First, it converts the string labels into their corresponding numerical labels for training purposes.\n",
    "    Then, it performs two checks. The first check ensures that the conversion to one-hot vectors\n",
    "    has been done correctly, meaning there are no labels without a logical one-hot vector representation.\n",
    "    The second check verifies if there are any None values in the training data. \n",
    "    If any None values are found, the program halts.\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_train_temp=np.zeros(Y_train.shape,dtype=np.int16)\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        Y_train_temp[i]=alphabets[Y_train[i]]\n",
    "\n",
    "    Y_train=Y_train_temp\n",
    "\n",
    "    del Y_train_temp\n",
    "    train_shuffler= np.random.permutation(X_train.shape[0])\n",
    "    X_train=X_train[train_shuffler]\n",
    "    Y_train=Y_train[train_shuffler]\n",
    "\n",
    "    Y_train=tf.one_hot(Y_train,depth=len(alphabets))\n",
    "    for item in Y_train:\n",
    "        if( not np.any(item) and np.sum(item)!=1):\n",
    "            assert(\"EROOR \")\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(30):\n",
    "            if(X_train[i][j][X_train[i][j]==None].shape[0] > 0 ):\n",
    "                assert(\"Error\")\n",
    "    return X_train,Y_train \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e197e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(sign,X_train,Y_train):\n",
    "    \"\"\"\n",
    "    Retraining the Model for a Specific Sign on New Data\n",
    "\n",
    "    Args:\n",
    "\n",
    "    sign (str): The name of the model that will be trained on the new data.\n",
    "    X_train (numpy.ndarray): Numpy array containing the new data that the model will be retrained on.\n",
    "    Y_train (numpy.ndarray): Numpy array containing the labels of the new data.\n",
    "    Returns:\n",
    "\n",
    "    None: This function only saves the model.\n",
    "    Description:\n",
    "    This function is responsible for retraining old models on new data, specifically the newly added signs to the system. Since the old models have not seen the newly added data, all the old models will be retrained using samples from the newly added sign.\n",
    "    \"\"\"\n",
    "    alphabets={sign:1,f\"not_{sign}\":0}\n",
    "    X_train,Y_train=handle_data(X_train,Y_train,alphabets)\n",
    "    model = load_old_model(alphabets,sign)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    callback = CustomCallback(os.path.join(os.getcwd(),\"models\",f\"{sign}_model.h5\"))\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    model.fit(X_train, Y_train,batch_size=32, epochs=800,verbose=1,callbacks=[callback])\n",
    "    model.save(os.path.join(os.getcwd(),\"models\",f\"{sign}_model.h5\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b593ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sign,X_train,Y_train):\n",
    "    \"\"\"\n",
    "    Training and Saving the Model for a Specific Sign\n",
    "\n",
    "    Args:\n",
    "\n",
    "    sign (str): The name of the sign for which the model will be dedicated.\n",
    "    X_train (numpy.ndarray): Numpy array containing the training data to train the model.\n",
    "    Y_train (numpy.ndarray): Numpy array containing the labels of the training data.\n",
    "    Returns:\n",
    "\n",
    "    None: This function only saves the model.\n",
    "    Description:\n",
    "    This function is responsible for training the models for a specific sign.\n",
    "    These models will be used to check the detection of the sign, acting as a checker for \n",
    "    its detection. The function takes the sign name, training data, and labels as input, \n",
    "    and saves the trained model for the sign.\n",
    "\n",
    "    \"\"\"\n",
    "    alphabets={sign:1,f\"not_{sign}\":0}\n",
    "    Y_train_temp=np.zeros(Y_train.shape,dtype=np.int16)\n",
    "\n",
    "    X_train,Y_train=handle_data(X_train,Y_train,alphabets)\n",
    "    model=create_model(alphabets)      \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    callback = CustomCallback(os.path.join(os.getcwd(),\"models\",f\"{sign}_model.h5\"))\n",
    "    model.fit(X_train, Y_train,batch_size=32, epochs=1700,verbose=1,callbacks=[callback])\n",
    "    model.save(os.path.join(os.getcwd(),\"models\",f\"{sign}_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_not_folder(not_vids,path_to_not_data,sign,index,path_to_vid):\n",
    "    \"\"\"\n",
    "    Creating the Folder for Samples of Signs that are not Equal to the Current Sign\n",
    "\n",
    "    Args:\n",
    "\n",
    "    not_vids (list): A list containing all the signs that are not equal to the current sign.\n",
    "    path_to_not_data (str): The directory that contains the folder of videos for signs that are not the current sign.\n",
    "    sign (str): The name of the current sign.\n",
    "    path_to_vid (str): The path to the folder of videos for the current sign.\n",
    "    Description:\n",
    "    This function creates the \"not_sign_folder\" which contains samples from all the signs that are not equal to the current sign. This folder is used to train the model to distinguish between the current sign and all the other signs. It takes the list of not equal signs, the path to the folder of videos for signs that are not the current sign, the name of the current sign, and the path to the folder of videos for the current sign.\n",
    "    \"\"\"\n",
    "    previous_rand=-1 \n",
    "    vids_num = len(os.listdir(os.path.join(path_to_not_data,sign)))\n",
    "    shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output0.avi\"),\n",
    "                    os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "    index+=1 \n",
    "    shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output{1}.avi\"),\n",
    "                    os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "    index+=1 \n",
    "\n",
    "    new_rand= np.random.randint(11,vids_num)\n",
    "    while (new_rand==previous_rand):\n",
    "        new_rand= np.random.randint(11,vids_num)\n",
    "\n",
    "    previous_rand=new_rand\n",
    "\n",
    "    shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output{new_rand}.avi\"),\n",
    "                    os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "    index+=1 \n",
    "\n",
    "    new_rand= np.random.randint(11,vids_num)\n",
    "    while (new_rand==previous_rand):\n",
    "        new_rand= np.random.randint(11,vids_num)\n",
    "\n",
    "    previous_rand = new_rand \n",
    "\n",
    "    shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output{new_rand}.avi\"),\n",
    "                    os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "    index+=1 \n",
    "\n",
    "    num_of_vid_in_sign=len(os.listdir(path_to_vid))\n",
    "\n",
    "    num_of_vid_in_not_sign=len(os.listdir(not_sign_path))\n",
    "\n",
    "    while(num_of_vid_in_not_sign > num_of_vid_in_sign):\n",
    "        new_rand=np.random.randint(0,num_of_vid_in_sign)\n",
    "        if(new_rand>=num_of_vid_in_sign-1):\n",
    "            continue \n",
    "        shutil.copyfile(os.path.join(path_to_vid,f\"output{new_rand}.avi\")\n",
    "                        ,os.path.join(path_to_vid,f\"output{num_of_vid_in_sign}.avi\"))\n",
    "        num_of_vid_in_sign=len(os.listdir(path_to_vid))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_data(sign_name,new_added_dir):\n",
    "    \"\"\"\n",
    "    Saving the Training Data\n",
    "\n",
    "    Args:\n",
    "\n",
    "    sign_name (str): The name of the sign.\n",
    "    new_added_dir (str): The path to the working directory used to save the data.\n",
    "    Returns:\n",
    "\n",
    "    None: This function only saves the data.\n",
    "    Description:\n",
    "    This function is responsible for saving the training data of the created signs. It takes the sign name and the path to the working directory as input and saves the data in the specified directory.\n",
    "    \"\"\"\n",
    "    if(os.path.exists(os.path.join(os.getcwd(),\"Data_points\",f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"))) : \n",
    "        os.remove(os.path.join(os.getcwd(),\"Data_points\",f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "    shutil.move(os.path.join(os.getcwd(),new_added_dir,f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"),\n",
    "                os.path.join(os.getcwd(),\"Data_points\"))\n",
    "\n",
    "    if(os.path.exists(os.path.join(os.getcwd(),\"Data_points\",f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"))) : \n",
    "        os.remove(os.path.join(os.getcwd(),\"Data_points\",f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "\n",
    "    shutil.move(os.path.join(os.getcwd(),new_added_dir,f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"),\n",
    "                os.path.join(os.getcwd(),\"Data_points\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f875a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y_train(new_added_dir,sign_name):\n",
    "    \"\"\"\n",
    "    Collecting and Returning Training Data\n",
    "\n",
    "    Args:\n",
    "\n",
    "    new_added_dir (str): The path to the working directory used to save the data.\n",
    "    sign_name (str): The name of the sign.\n",
    "    Returns:\n",
    "\n",
    "    X_train (numpy.ndarray): The collected data, ready for training.\n",
    "    Y_train (numpy.ndarray): The labels of the collected data.\n",
    "    Description:\n",
    "    This function is responsible for collecting the data and returning it in the form of X_train and Y_train. It takes the path to the working directory and the sign name as input. The function collects the data from the specified directory and returns the collected data along with its corresponding labels.\n",
    "    \"\"\"\n",
    "    os.remove(os.path.join(new_added_dir,f\"{sign_name}\",\"no_aug.npy\"))\n",
    "    shutil.move(os.path.join(os.getcwd(),new_added_dir,sign_name),\n",
    "                os.path.join(os.getcwd(),\"data_videos\",sign_name))\n",
    "    shutil.rmtree(os.path.join(os.getcwd(),new_added_dir,f\"not_{sign_name}\"))\n",
    "    X_train=np.load(os.path.join(os.getcwd(),\"Data_points\",f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "    Y_train=np.load(os.path.join(os.getcwd(),\"Data_points\",f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "    return X_train, Y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1250fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choice = int (input(\"Choose to record new videos=>0 or you have data in the new added vidoes folder ==>1\"))\n",
    "\n",
    "path_to_videos=os.path.join(os.getcwd(),\"data_videos/\")\n",
    "list_of_vids = os.listdir(path_to_videos)\n",
    "\n",
    "for sign_video_index in list_of_vids:\n",
    "    \n",
    "    sign_name=sign_video_index\n",
    "    shutil.move(os.path.join(path_to_videos,sign_name),\n",
    "                os.path.join(os.getcwd(),\"New_added_Videos\"))\n",
    "    new_added_dir = os.path.join(os.getcwd(),\"New_added_Videos\")\n",
    "    while True:\n",
    "        if(os.path.exists(os.path.join( new_added_dir,sign_name))):\n",
    "            path_to_vid = os.path.join(os.getcwd(),\"New_added_Videos\",sign_name)\n",
    "            break \n",
    "        else : \n",
    "            sign_name=(input(\"Please enter valid name of the sign\"))\n",
    "            path_to_vid = os.path.join(os.getcwd(),\"New_added_Videos\",sign_name)\n",
    "    path_to_not_data=os.path.join(os.getcwd(),\"data_videos\") \n",
    "    not_vids = os.listdir(path_to_not_data)\n",
    "    print(not_vids)\n",
    "    not_sign_path=os.path.join(new_added_dir,f\"not_{sign_name}\")\n",
    "    os.mkdir(not_sign_path)\n",
    "    index = 0\n",
    "    previous_rand=-1 \n",
    "    for sign in not_vids: \n",
    "\n",
    "        create_not_folder(not_vids,path_to_not_data,sign,index,path_to_vid)\n",
    "\n",
    "\n",
    "    all_vids=[f\"{sign_name}\",f\"not_{sign_name}\"]\n",
    "\n",
    "    generate_training_data(all_vids, new_added_dir)\n",
    "    collect_data(all_vids,sign_name,new_added_dir)\n",
    "\n",
    "    save_training_data(sign_name,new_added_dir)  \n",
    "\n",
    "    X_train,Y_train= get_X_Y_train(new_added_dir,sign_name)\n",
    "    train_model(sign_name,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3317ef",
   "metadata": {},
   "source": [
    "## retrain the previous trained models to adapt with the new signs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddab97e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def retrain_more_signs(new_list):\n",
    "    \"\"\"\n",
    "    retrain more signs and get more models for them \n",
    "    \n",
    "    Args: \n",
    "    new_list(list): the list of signs that will be added \n",
    "    \n",
    "    Returns : \n",
    "    None \n",
    "    \n",
    "    Description : \n",
    "    this function is used if you want to add new signs , it will retrain all the previous model , \n",
    "    so it's suggest to use this funciion with big new list not with few ones , becuase all the models \n",
    "    will be trained . \n",
    "    the function sample four videos from all new list and put them in the not_sign for the model which \n",
    "    is re-trained and it will loop over all models , to let the old models to learn that the new signs \n",
    "    don't belong to them  , to be able to differintiate between the signs \n",
    "    \"\"\" \n",
    "    except_list=[]\n",
    "    entire_data_path = os.path.join(os.getcwd(),\"data_videos/\")\n",
    "    entire_list=os.listdir(entire_data_path)\n",
    "    old_list=[]\n",
    "    for i in entire_list :\n",
    "        if i not in new_list:\n",
    "            old_list.append(i)\n",
    "\n",
    "    print(old_list)\n",
    "\n",
    "    new_data_path  = os.path.join(os.getcwd(),\"New_added_Videos/\")\n",
    "    for i in old_list:\n",
    "        if(i in except_list ) : continue \n",
    "        not_sign_path = os.path.join(new_data_path,f\"not_{i}\")\n",
    "        os.mkdir(not_sign_path) ; \n",
    "        index = 0  \n",
    "        for j in new_list:\n",
    "            path_to_curr_sign=os.path.join(entire_data_path,j)\n",
    "            shutil.copyfile(os.path.join(path_to_curr_sign,f\"output{0}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "            shutil.copyfile(os.path.join(path_to_curr_sign,f\"output{1}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "            curr_sign_num_vids = len(os.listdir(path_to_curr_sign))\n",
    "            rand_int = np.random.randint(2,curr_sign_num_vids)\n",
    "\n",
    "            shutil.copyfile(os.path.join(path_to_curr_sign,f\"output{rand_int}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "\n",
    "            rand_int = np.random.randint(2,curr_sign_num_vids)\n",
    "\n",
    "            shutil.copyfile(os.path.join(path_to_curr_sign,f\"output{rand_int}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "            print(j)\n",
    "\n",
    "\n",
    "\n",
    "        num_of_not_sign = len (os.listdir(not_sign_path))\n",
    "        os.mkdir(os.path.join(new_data_path,i))\n",
    "        index = 0 \n",
    "        for k in range(num_of_not_sign): \n",
    "            num_of_sign= len(os.listdir(os.path.join(entire_data_path,i)))\n",
    "            randint = np.random.randint(0 ,num_of_sign-1)\n",
    "            shutil.copyfile(os.path.join(entire_data_path,i,f\"output{randint}.avi\"),\n",
    "                           os.path.join(new_data_path,i,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "\n",
    "        all_vids=[f\"{i}\",f\"not_{i}\"]\n",
    "\n",
    "        generate_training_data(all_vids, new_data_path)\n",
    "        collect_data(all_vids,i,new_data_path,True)\n",
    "\n",
    "        path_to_data_points = os.path.join(os.getcwd(),\"Data_points\")\n",
    "\n",
    "        old_X_train= np.load(os.path.join(path_to_data_points,\n",
    "                                          f\"Data_train_clown_40_no_aug_yes_no_{i}.npy\"))\n",
    "        old_Y_train= np.load(os.path.join(path_to_data_points,\n",
    "                                          f\"Data_labels_clown_40_no_aug_yes_no_{i}.npy\"))\n",
    "\n",
    "        X_temp_train=np.load(os.path.join(new_data_path,\n",
    "                                         f\"Data_train_clown_40_no_aug_yes_no_{i}_additional.npy\"))\n",
    "        Y_temp_train= np.load(os.path.join(new_data_path,\n",
    "                                          f\"Data_labels_clown_40_no_aug_yes_no_{i}_additional.npy\"))\n",
    "\n",
    "        X_train=np.concatenate([old_X_train,X_temp_train])\n",
    "        Y_train=np.concatenate([old_Y_train,Y_temp_train])\n",
    "        retrain_model(i,X_train,Y_train)\n",
    "\n",
    "        if(os.path.exists(os.path.join(path_to_data_points,f\"Data_train_clown_40_no_aug_yes_no_{i}.npy\"))):\n",
    "            os.remove(os.path.join(path_to_data_points,f\"Data_train_clown_40_no_aug_yes_no_{i}.npy\"))\n",
    "            np.save(os.path.join(path_to_data_points,f\"Data_train_clown_40_no_aug_yes_no_{i}.npy\"),X_train)\n",
    "\n",
    "        if(os.path.exists(os.path.join(path_to_data_points,f\"Data_labels_clown_40_no_aug_yes_no_{i}.npy\"))):\n",
    "            os.remove(os.path.join(path_to_data_points,f\"Data_labels_clown_40_no_aug_yes_no_{i}.npy\"))\n",
    "            np.save(os.path.join(path_to_data_points,f\"Data_labels_clown_40_no_aug_yes_no_{i}.npy\"),Y_train)\n",
    "\n",
    "        shutil.rmtree(os.path.join(new_data_path,i))\n",
    "        shutil.rmtree(os.path.join(new_data_path,f\"not_{i}\"))\n",
    "        os.remove(os.path.join(new_data_path,\n",
    "                               f\"Data_labels_clown_40_no_aug_yes_no_{i}_additional.npy\"))\n",
    "\n",
    "        os.remove(os.path.join(new_data_path,\n",
    "                               f\"Data_train_clown_40_no_aug_yes_no_{i}_additional.npy\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f799665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "################################33back up \n",
    "\n",
    "\n",
    "# choice = int (input(\"Choose to record new videos=>0 or you have data in the new added vidoes folder ==>1\"))\n",
    "choice = 1 ;\n",
    "path_to_videos=os.path.join(os.getcwd(),\"data_videos/\")\n",
    "list_of_vids = os.listdir(path_to_videos)\n",
    "\n",
    "for sign_video_index in list_of_vids:\n",
    "\n",
    "    if (choice ==1 ): \n",
    "        print(\"Vidoes\")\n",
    "        sign_name=sign_video_index\n",
    "        shutil.move(os.path.join(path_to_videos,sign_name),\n",
    "                    os.path.join(os.getcwd(),\"New_added_Videos\"))\n",
    "        new_added_dir = os.path.join(os.getcwd(),\"New_added_Videos\")\n",
    "        while True:\n",
    "            if(os.path.exists(os.path.join( new_added_dir,sign_name))):\n",
    "                path_to_vid = os.path.join(os.getcwd(),\"New_added_Videos\",sign_name)\n",
    "                break \n",
    "            else : \n",
    "                sign_name=(input(\"Please enter valid name of the sign\"))\n",
    "                path_to_vid = os.path.join(os.getcwd(),\"New_added_Videos\",sign_name)\n",
    "        # first secinario , there is no previous data , and no retrain , just new sign \n",
    "        path_to_not_data=os.path.join(os.getcwd(),\"data_videos\") \n",
    "        not_vids = os.listdir(path_to_not_data)\n",
    "        print(not_vids)\n",
    "        not_sign_path=os.path.join(new_added_dir,f\"not_{sign_name}\")\n",
    "        os.mkdir(not_sign_path)\n",
    "        index = 0\n",
    "\n",
    "        previous_rand=-1 \n",
    "        for sign in not_vids: \n",
    "\n",
    "            vids_num = len(os.listdir(os.path.join(path_to_not_data,sign)))\n",
    "    #         print(vids_num)\n",
    "            shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output0.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "            shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output{1}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "\n",
    "            new_rand= np.random.randint(11,vids_num)\n",
    "            while (new_rand==previous_rand):\n",
    "                new_rand= np.random.randint(11,vids_num)\n",
    "\n",
    "            previous_rand=new_rand\n",
    "\n",
    "            shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output{new_rand}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "\n",
    "            new_rand= np.random.randint(11,vids_num)\n",
    "            while (new_rand==previous_rand):\n",
    "                new_rand= np.random.randint(11,vids_num)\n",
    "\n",
    "            previous_rand = new_rand \n",
    "\n",
    "            shutil.copyfile(os.path.join(path_to_not_data,sign,f\"output{new_rand}.avi\"),\n",
    "                            os.path.join(not_sign_path,f\"output{index}.avi\"))\n",
    "            index+=1 \n",
    "\n",
    "            num_of_vid_in_sign=len(os.listdir(path_to_vid))\n",
    "\n",
    "            num_of_vid_in_not_sign=len(os.listdir(not_sign_path))\n",
    "    #         print(num_of_vid_in_sign)\n",
    "    #         print(num_of_vid_in_not_sign)\n",
    "            while(num_of_vid_in_not_sign > num_of_vid_in_sign):\n",
    "                new_rand=np.random.randint(0,num_of_vid_in_sign)\n",
    "                if(new_rand>=num_of_vid_in_sign-1):\n",
    "                    continue \n",
    "                shutil.copyfile(os.path.join(path_to_vid,f\"output{new_rand}.avi\")\n",
    "                                ,os.path.join(path_to_vid,f\"output{num_of_vid_in_sign}.avi\"))\n",
    "                num_of_vid_in_sign=len(os.listdir(path_to_vid))\n",
    "                print(\"Peop\",num_of_vid_in_sign,num_of_vid_in_not_sign)\n",
    "\n",
    "\n",
    "\n",
    "        all_vids=[f\"{sign_name}\",f\"not_{sign_name}\"]\n",
    "\n",
    "        generate_training_data(all_vids, new_added_dir)\n",
    "        collect_data(all_vids,sign_name,new_added_dir)\n",
    "        print(new_added_dir)\n",
    "        if(os.path.exists(os.path.join(os.getcwd(),\"Data_points\",f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"))) : \n",
    "            os.remove(os.path.join(os.getcwd(),\"Data_points\",f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "        shutil.move(os.path.join(os.getcwd(),new_added_dir,f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"),\n",
    "                   os.path.join(os.getcwd(),\"Data_points\"))\n",
    "\n",
    "        if(os.path.exists(os.path.join(os.getcwd(),\"Data_points\",f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"))) : \n",
    "            os.remove(os.path.join(os.getcwd(),\"Data_points\",f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "\n",
    "        shutil.move(os.path.join(os.getcwd(),new_added_dir,f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"),\n",
    "                    os.path.join(os.getcwd(),\"Data_points\"))  \n",
    "\n",
    "    #     for vid in all_vids:\n",
    "    #         os.remove(os.path.join(new_added_dir,f\"{sign_name}\",\"no_aug.npy\"))\n",
    "        os.remove(os.path.join(new_added_dir,f\"{sign_name}\",\"no_aug.npy\"))\n",
    "        shutil.move(os.path.join(os.getcwd(),new_added_dir,sign_name),\n",
    "                    os.path.join(os.getcwd(),\"data_videos\",sign_name))\n",
    "        shutil.rmtree(os.path.join(os.getcwd(),new_added_dir,f\"not_{sign_name}\"))\n",
    "        X_train=np.load(os.path.join(os.getcwd(),\"Data_points\",f\"Data_train_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "        Y_train=np.load(os.path.join(os.getcwd(),\"Data_points\",f\"Data_labels_clown_40_no_aug_yes_no_{sign_name}.npy\"))\n",
    "        train_model(sign_name,X_train,Y_train)\n",
    "\n",
    "    else : \n",
    "        print(\"recording\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afc7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
